import telebot
import google.generativeai as genai
# --- –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ê–ï–ú –≠–¢–û–¢ –ò–ú–ü–û–†–¢ ---
# from google.generativeai import types as genai_types 
import os
import threading
from flask import Flask
import logging
import sys
import time
from telebot import types
from telebot.types import BotCommand
import re
from google.api_core import exceptions as google_exceptions

# --- –ù–ê–°–¢–†–û–ô–ö–ê –õ–û–ì–ò–†–û–í–ê–ù–ò–Ø ---
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler(sys.stdout)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# --- –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ, —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–º–µ–Ω–∞ –º–æ–¥–µ–ª–µ–π ---
MODEL_FLASH = 'gemini-2.5-flash'
MODEL_PRO = 'gemini-2.5-pro'
DEFAULT_MODEL_NAME = 'flash'

# --- –•–†–ê–ù–ò–õ–ò–©–ê –î–ê–ù–ù–´–• ---
user_histories = {}
user_model_choices = {}

def to_telegram_markdown(text):
    text = text.replace('**', '*')
    special_chars = r"([.>#+-=|{!}()])"
    return re.sub(special_chars, r'\\\1', text)

# --- –í–ï–ë-–°–ï–†–í–ï–† ---
app = Flask(__name__)
@app.route('/')
def hello_world():
    return 'Bot is alive!'

def run_web_server():
    try:
        port = int(os.environ.get("PORT", 8000))
        app.run(host='0.0.0.0', port=port)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–µ: {e}", exc_info=True)

# --- –û–°–ù–û–í–ù–ê–Ø –ß–ê–°–¢–¨ –ë–û–¢–ê ---
if __name__ == "__main__":
    try:
        logger.info("--- –ó–ê–ü–£–°–ö –°–ö–†–ò–ü–¢–ê –ë–û–¢–ê ---")

        TELEGRAM_BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
        GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
        
        if not TELEGRAM_BOT_TOKEN or not GEMINI_API_KEY:
            raise ValueError("–û–®–ò–ë–ö–ê: API-–∫–ª—é—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        
        logger.info("API –∫–ª—é—á–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω—ã.")

        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TeleBot...")
        bot = telebot.TeleBot(TELEGRAM_BOT_TOKEN)
        logger.info("TeleBot —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

        logger.info("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Google Generative AI...")
        genai.configure(api_key=GEMINI_API_KEY)
        logger.info("Google Generative AI —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω.")
        
        try:
            logger.info("–ü–æ–ø—ã—Ç–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞...")
            bot.set_my_commands([
                BotCommand('start', '–ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞'),
                BotCommand('reset', '–°–±—Ä–æ—Å–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é'),
                BotCommand('model', '–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å')
            ])
            logger.info("–ö–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞ —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã –±–æ—Ç–∞: {e}", exc_info=True)

        # –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î
        @bot.message_handler(commands=['start', 'reset', 'model'])
        def handle_commands(message):
            if message.text == '/start':
                bot.reply_to(message, "–ü—Ä–∏–≤–µ—Ç! –Ø –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Gemini (–ø–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è —Ç–µ—Å—Ç–∞).")
            # ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
            elif message.text == '/reset':
                user_id = message.chat.id
                if user_id in user_histories:
                    user_histories.pop(user_id)
                bot.reply_to(message, "–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ —Å–±—Ä–æ—à–µ–Ω–∞.")
            elif message.text == '/model':
                markup = types.InlineKeyboardMarkup(row_width=2)
                btn_flash = types.InlineKeyboardButton("‚ö°Ô∏è Flash", callback_data='select_flash')
                btn_pro = types.InlineKeyboardButton("üíé Pro", callback_data='select_pro')
                markup.add(btn_flash, btn_pro)
                user_id = message.chat.id
                current_model_name = user_model_choices.get(user_id, DEFAULT_MODEL_NAME)
                text_to_send = f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: *{current_model_name.capitalize()}*.\n–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤—É—é:"
                bot.send_message(user_id, to_telegram_markdown(text_to_send), 
                                 reply_markup=markup, parse_mode='MarkdownV2')

        @bot.callback_query_handler(func=lambda call: call.data.startswith('select_'))
        def handle_model_selection(call):
            user_id = call.message.chat.id
            model_text = ""
            if call.data == 'select_flash':
                user_model_choices[user_id] = 'flash'
                model_text = "‚ö°Ô∏è Flash"
            elif call.data == 'select_pro':
                user_model_choices[user_id] = 'pro'
                model_text = "üíé Pro"
            
            bot.answer_callback_query(call.id, text=f"–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å {model_text}")
            text_to_send = f"–û—Ç–ª–∏—á–Ω–æ! –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: *{model_text}*"
            bot.edit_message_text(chat_id=user_id, message_id=call.message.message_id, 
                                  text=to_telegram_markdown(text_to_send), parse_mode='MarkdownV2')

        @bot.message_handler(func=lambda message: True)
        def get_gemini_response(message):
            user_id = message.chat.id
            thinking_message = bot.reply_to(message, "‚è≥ –î—É–º–∞—é...")
            try:
                chosen_model_name = user_model_choices.get(user_id, DEFAULT_MODEL_NAME)
                model_name = MODEL_PRO if chosen_model_name == 'pro' else MODEL_FLASH
                model = genai.GenerativeModel(model_name)
                history = user_histories.get(user_id, [])
                history.append({'role': 'user', 'parts': [message.text]})
                
                # --- –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ê–ï–ú –ü–û–ò–°–ö ---
                # tool = genai_types.Tool(google_search=genai_types.GoogleSearch())
                # response = model.generate_content(history, tools=[tool])
                response = model.generate_content(history) # <--- –í—ã–∑—ã–≤–∞–µ–º –±–µ–∑ tools

                bot_response_text = response.text if response.parts else "–ù–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."
                history.append({'role': 'model', 'parts': [bot_response_text]})
                if len(history) > MAX_HISTORY_LENGTH:
                    history = history[-MAX_HISTORY_LENGTH:]
                user_histories[user_id] = history
                formatted_text = to_telegram_markdown(bot_response_text)
                if len(formatted_text) > 4096:
                    formatted_text = formatted_text[:4093] + '...'
                bot.edit_message_text(chat_id=user_id, message_id=thinking_message.message_id, 
                                      text=formatted_text, parse_mode='MarkdownV2')
            except Exception as e:
                logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ Gemini: {e}", exc_info=True)
                bot.edit_message_text(chat_id=user_id, message_id=thinking_message.message_id, text="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

        logger.info("–ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ...")
        web_thread = threading.Thread(target=run_web_server)
        web_thread.daemon = True
        web_thread.start()
        logger.info("–í–µ–±-—Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω.")

        logger.info("--- –ó–ê–ü–£–°–ö –ë–û–¢–ê (POLLING) ---")
        bot.polling(none_stop=True)

    except Exception as e:
        logger.error(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ù–ê –í–ù–ï–®–ù–ï–ú –£–†–û–í–ù–ï: {e}", exc_info=True)
        time.sleep(60)